[{"_index": "cv", "_type": "docket", "_id": "7", "_score": 3.366206, "_source": {"title": "Big Data Engineer & DevOps", "experience": [{"title": "Big Data Engineer", "duration": 18, "description": "Managing Oracle Big Data Appliance Cluster Managing Oracle Big Data SQL Managing Oracel Exadata Appliance Cluster Managing Microsoft SQL Server Managing MySQL Server- Percona Managing AWS Redshift, DynamoDB, RDS, EC2 and S3 bucket Devops : Jenkins, Github, Flyway, Code Commit, Code Deploy, Code Pipeline, Elastic Beanstalk Data Engineering: Python, Airflow Infrastructure as Code : Terraform, CLoudFormation, Troposphere"}], "skills": ["Unix", "Oracle Database", "Microsoft SQL Server", "Hadoop", "MongoDB", "Oracle RAC", "RMAN", "Oracle Enterprise Manager", "EXADATA", "CASSANDRA", "Exadata", "Data Guard", "Hive"]}}, {"_index": "cv", "_type": "docket", "_id": "8", "_score": 3.32844, "_source": {"title": "senior Data Scientist and Machine Learning Engineer", "experience": [{"title": "Data scientist and engineer", "duration": 73, "description": "Data Science, Product, Strategy and Engineering - I advise companies including FMCG, Tech companies, Telco on leveraging their data and converting that into business value. (2014 - now) - Clients include venture-backed companies funded by Index Ventures, Balderton Capital, Northzone and other top investors. - My engagements range from proof of concepts and workshops to private executive briefings. - Data strategy engagement for a major fintech player. - Data Strategy and analysis work for early stage companies - Delivering compliant Data Science infrastructure to a larger financial institution - Delivering bespoke Bayesian models for various companies including retail companies. - Owning and improving the data engineering infrastructure for a fast growing mobile app Edtech startup using Terraform, Snowplow Analytics, Jenkins, Python, AWS Lambdas and Kinesis.  Mentor - I mentor Junior Data Scientists and Engineers, and am particularly interested in helping members of under-represented communities speak at Tech conferences. (2016 - now)  Teaching Assistant and Lecturer: - General Assembly (2016 - now) - University of Luxembourg internal workshops (2013)  Speaker: - I mostly speak about deploying data science and probabilistic programming (2013 - Now)"}, {"title": "Data Scientist", "duration": 12, "description": "Elevate Direct is a highly sophisticated AI and machine learning talent acquisition platform, specially designed to increase the productivity of your talent function and hiring communities across all workforce categories.  I worked on the data product side bringing R and D to production. I also worked on sales and marketing analysis to enhance our value proposition. My business development work brought in revenue and finally I taught classes internally on AI.  I work with technologies such as Python, Tensorflow and Spark - for building and maintaining our data products. I built some Convolutional Neural Network models and evaluated some of the infrastructure for deploying these models.  In conjunction to shipping data products - such as the market ranking functionality (with a small team) I also wrote some PR pieces, did blog posts, presented research on Variational Inference internally, did a webinar and spoke publicly about Elevate Direct."}], "skills": ["Business Strategy", "Numerical Analysis", "Data Analysis", "Optimization", "Forecasting", "Cloud Computing", "Agile Methodologies", "Programming", "Statistics", "Machine Learning", "Big Data", "Algorithms", "Software Engineering", "Computer Science", "Research", "Analysis", "Economics", "Statistical Modeling", "Data Mining", "Shell Scripting", "Database Administration", "Mathematical Modeling", "Physics", "Python", "SQL", "Databases", "Git", "Mathematica", "MySQL", "Unix", "Linux", "Matlab", "LaTeX", "R", "Interpersonal Skills", "Public Speaking", "Data Science", "Unsupervised Learning", "Dimensional Modeling", "Clojure", "Logistic Regression", "Linear Regression", "Applied Probability", "Differential Equations", "Applied Mathematics", "Mathematical Physics", "Quantitative Finance", "Quantum Theory"]}}, {"_index": "cv", "_type": "docket", "_id": "4", "_score": 3.0537386, "_source": {"title": "Data Engineer", "experience": [{"title": "Data Engineer", "duration": 19, "description": "The Big Data Engineer programme is a technical journey where I acquire through deep learning methodologies, knowledge and hands-on skills that will allow me to be productive within the business environment.  Courses and Accreditation  - Professional skills - Web applications and coding - GIT, GITHUB and Agile - Introduction to data analytics - Data modelling principles - SQL and T-SQL - Python and data munging techniques - NoSQL using MongoDB and Neo4j - Cloudera Hadoop Ecosystem including Sqoop, Pig & Flume - Apache Spark - Python  Accreditation - Cloudera CCA Developer - CISI IOC (Investment & Securities) "}], "skills": ["Github", "MongoDB", "Docker", "maven", "Big Data Analytics", "SQL", "Spark"]}}, {"_index": "cv", "_type": "docket", "_id": "9", "_score": 1.4169712, "_source": {"title": "ERP Consultant, Business Analyst, Project Manager, Data Analyst", "experience": [{"title": "ERP Application and Technical Consultant", "duration": 25, "description": "Working on projects of delivering and implementing ERP solutions for international manufacturing companies. Main activity is to develop projects to integrate the various functions and departments in a manufacturing facility to have control on the entire organization. That includes providing technical feasibility of future business process after analyzing current state, business requirements and constraints. Identifying the business needs and performed fit gap analysis. Suggesting project processes for improved timely and quality delivery of project. Responsible for optimizing the system for easy use, training employees in its functions and drive User acceptance tests."}, {"title": "Business Solutions Consultant", "duration": 14, "description": "I\u2019m responsible for bringing business and technology together under a unified structure. Also in charge of exciting transformational programs and projects that involve controlling a multi-disciplinary teams from various fields. Working as Admin and Specialist of ERP Infor XA. After less than one year I proved myself and CEO trusted me and gave opportunity to implement ERP solution from R7.8 to R9. A project where I organized, planned and performed project on very high level. During the project I took care of most of tasks, tested all its features and modules which helped me to understand the ERP solution at global, I also educated/trained over 100 people for new system, wrote instructions, guidelines and documentation to help them adapt and as well to new potential ERP users. With it I became XA Consultant for all Business Processes inside of company. I\u2019m working as well as System Admin (IBM iSeries 5/7+, AS/400), working with queries, DB and creating programs for our ERP. I performed migration of ERP and all its applications from AS/400 iSeries 5 to Power720 with Mirroring technology (PowerHA). I was associate in several projects for Finance, MRP, Sales and Technical dept. which helped me to gain knowledge from real life practices and able to use it as ERP specialist. I\u2019m also named as Project Manager for web-based application running on Domino and workflow platform and operate as its admin. I take charge of most reporting, with my understanding of business processes and strong analytical skills I created series of programs to automate complex reports through Excel / SQL / VBA using external data like DB2 for various depts, their employees and CEO members so they are able to get quickly live reports and needed information. Their satisfaction to my programs, trainings and support is one of the biggest successes of mine. I\u2019ve been working with business partners and consultants from Europe and USA with huge experience and knowledge and I deserved their utmost respect."}], "skills": ["System Administration", "Project Management", "IT Management", "ERP", "Software Project Management", "Scrum", "Project Planning", "Product Management", "Data Analysis", "Data Migration", "Data Warehousing", "IT Strategy", "IT Service Management", "Information Technology"]}}, {"_index": "cv", "_type": "docket", "_id": "11", "_score": 1.2304206, "_source": {"title": "Senior Big Data Engineer", "experience": [{"title": "Big Data Scala Engineer", "duration": 42, "description": "Building a greenfield IoT big data analytics platform from scratch, for the Hive home hub product, using the latest technology in the field:  The platform we've built is capable of processing the Hive IoT firehose Kafka data stream, which generates more that 4 billion messages per day in near realtime to apply data analytics algorithms and create value add data products, such as heating efficiency monitoring and occupancy detection. Our streaming data processing jobs are capable at running at message rates in excess of 100k/sec, not theoretical but observed.  I've played a key role in introducing Docker containerisation to the team to allow for complex testing of pipelines and this has led to us now having dozens of streaming data pipelines in production deployed using Docker containers on Kubernetes and Helm. We also operate a you build it, you run it approach which we self manage and fully support all our software in production 24/7.  We favour a 12 factor app approach to containerise our big data pipelines - this allows us to to take a share nothing approach between our pipelines and gives us the freedom to evolve the platform. I like to refer to it as The Polyglot Data Platform.  Our tech stack currently looks like Scala Python Kafka Cassandra Elasticsearch Spark Spark Streaming Kafka Streaming Docker - testing and deployment Kubernetes - deployments Helm charts AWS"}, {"title": "senior software engineer", "duration": 4, "description": "Project - Merchant Feed Service Worked as part of an agile cross functional team to deliver new API services that enable very large merchants to bulk list inventory from popular ecommerce platforms.  Working within a highly agile environment with a dedication to XP practices such as full time pair programming and TDD principles, we implemented a highly scalable solution using Scala REST services (spray) and the AKKA messaging framework to enable efficient handling of very large inventory uploads from merchants.  Project - Find a Garage service (Germany) Integrated 3rd party REST API to allow eBay to offer price a price comparison service for car repairs. The application was delivered using eBay standard application stack, built on top of Spring framework technologies. Introduced crucible for code reviews. Provided application architectural guidance. 100% pair programming.  - Scala, Spray, AKKA - Camel - Cassandra, - MySQL - REST \u2013 Jersey, spring MVC rest support. Restassured - JPA \u2013 Hibernate - Spring stack - Javascript / CSS - Jenkins CI "}], "skills": ["Java Enterprise Edition", "Spring Framework", "SQL", "MySQL", "Hibernate", "REST", "Unix", "Github", "MongoDB", "Amazon Web Services (AWS)", "Maven", "Docker", "Continuous Delivery", "BDD", "Big Data Analytics", "Apache Spark", "ElasticSearch", "Cassandra"]}}, {"_index": "cv", "_type": "docket", "_id": "6", "_score": 0.6786925, "_source": {"title": "senior Data Scientist", "experience": [{"title": "senior Data Scientist", "duration": 14, "description": "Supervised learning, optimisation, pandas, scikit-learn, pyspark, hive, jupyter"}, {"title": "senior Data Scientist", "duration": 13, "description": "Predictive modeling, pandas, scikit-learn, python, jupyter, matplotlib, bokeh, exasol, numpy, sql"}, {"title": "Data Scientist", "duration": 24, "description": "Revenue optimization for hotels metasearch engines. Data mining of hotel information. Machine learning modeler.  Technologies: - Python - Pandas - Numpy - Bokeh - MongoDB"}], "skills": ["Databases", "SQL", "Microsoft Excel", "Pandas", "Microsoft Office", "VBA", "JavaScript", "PySpark", "Quantitative Finance", "Regression Models", "Logistic Regression", "Data Science", "Scikit-Learn", "NumPy", "Apache Spark", "Hive"]}}, {"_index": "cv", "_type": "docket", "_id": "5", "_score": 0.6348883, "_source": {"title": "Senior Business Intelligence Analyst", "experience": [{"title": "Senior Business Intelligence Analyst", "duration": 8, "description": "- Develop Business Intelligence solutions for Marketing (website conversions, tracking, attribution), Finance (Income reconciliation from Salesforce data, Usage Cost, AR), CRM (Email Campaign performance)and School Usage using Qlikview, QlikSense, NPrinting, Power BI, SQL, MS SQL Server, SSRS, SSIS, Excel, R, Google Adwords, Salesforce. - Build automation framework for several reports, reduced processing time in general - Develop numerous ad-hoc queries and reports to collect and present information that satisfied clients and contributed to achieve organizational goals.  - Train various business unit teamson the effective use of processes, tools, and resources"}, {"title": "Business Improvement Analyst", "duration": 24, "description": "- Create reports using Business Objects with aim of improving the business - Create bespoke Business Intelligence solutions for the business - Performance reporting  #Achievements: Created a Business Intelligence system with MS Access that calculated the best new housing patches based on scoring for different weighting elements. I received a bonus for the creation of this system"}], "skills": ["SQL", "SSRS", "Crystal Reports", "Microsoft Excel", "Business Objects", "Access", "PL/SQL", "Databases", "Oracle", "MS Access", "MS Excel", "SSIS", "SAP BusinessObjects"]}}, {"_index": "cv", "_type": "docket", "_id": "3", "_score": 0.6012281, "_source": {"title": "senior Data Scientist/Engineer", "experience": [{"title": "Senior Data Scientist/ ML Engineer", "duration": 8, "description": "Collaboration in the design and implementation of an intelligent solution for AI Health Suite (Clinical Coding). - Natural Language Processing - A recent approach for Deep learning in text classifications: LSTM/GRU, CNN, Hierarchical Attention network and Multitask Learning - Python - CLoud solutions: Azure GPU-VM, Azure Cosmos DB, SQL, Google cloud: GC TPU/GPU VM, GC Bigquery, Spark  Design and development of an intelligent city platform by integrating AI with Agent-based model for transportation data and all relevant city information dataset. - Agent-based Simulation - Deep learning/ RNN-LSTM - Python - Bing REST API - Google Map API - Azure VM-GPU and CosmosDB"}, {"title": "Data Engineer/Scientist", "duration": 5, "description": "Deep learning in TR: - Stock price prediction using Deep learning methods: (RNN_LSTM) - Automatic extraction of breaking news events using NLP methods (Deep learning: RNN and CNN) - Fraud detection using Deep learning- ANN/ Regression and unsupervised deep (SOM) Big Data Handling in TR: - Data migration to Google Cloud Bigquery and Bigtable - Handling big data using Graph Database-Neo4j on Google Cloud and Azure - Data migration to Azure Cosmos Db"}, {"title": "Data Engineer/Scientist", "duration": 3, "description": "As part of Microsoft-Accenture-Avanade team, we took the concept of RPA a step further; Where we incorporate intelligence by deploying cognitive technologies from Microsoft Azure services to RPA platforms, to combine Machine Learning, Natural-language Processing and process automation, to perform complex tasks without human interference. Deep learning in Accenture: Insurance Claim Handling using Deep learning (CNN): - Prediction of damage costs - Document classification - Claim anti-Fraud Recovery - Settlement Strategy Microsoft Cloud Solutions in Accenture: - Azure Cloud GPU - Azure Machine Learning, Studio and Workbench - Azure Power-BI"}], "skills": ["Mechanical Engineering", "Numerical Analysis", "Robotics", "Fluid Mechanics", "Thermodynamics", "Photovoltaics", "Painting", "Mathematical Modeling", "Engineering", "Simulations", "Modeling", "Programming", "Data Analysis", "Machine Learning", "Cloud Computing", "ANSYS", "AutoCAD", "Microsoft Office", "SolidWorks", "Abaqus", "LabVIEW", "Matlab", "Java", "UGS NX", "Python", "Microsoft Azure", "Tensor Flow"]}}, {"_index": "cv", "_type": "docket", "_id": "1", "_score": 0.5978496, "_source": {"title": "Business Intelligence Architect", "experience": [{"title": "Business Intelligence Architect", "duration": 38, "description": "Designing and implementing systems that provide for the quality assurance of the company`s information and data. Business Intelligence endorsements for Business Intelligence systems implementation, working with the Head of Business Intelligence and relevant stakeholders for each business area. Working with the Business Systems team to define and implement data backup and security of information assets. Providing integral support when implementing new systems, preparing user training material and technical documentation."}], "skills": ["Business Intelligence", "Data Warehousing", " Reporting & Analysis", "Databases"]}}, {"_index": "cv", "_type": "docket", "_id": "13", "_score": 0.2374218, "_source": {"title": "Senior Business Intelligence Developer", "experience": [{"title": "Senior Business Intelligence Developer", "duration": 14, "description": "Creation of a Data Warehouse: - Marketing & Finance Data Mart. - Designed the ETL using SSIS using Kimball design methodology and optimizing the Data Warehouse loading time (the legacy Data Warehouse was taking 2 hours every nights and the current one that I have designed from scratch takes less than 20 minutes and is being refreshed every hours). - Creation of SSAS cubes to feed Dashboards for the Marketing & Finance Senior Management Team. - Creation of Marketing Dashboard using SSRS and other marketing experience reports (Enquiry/Lead conversion) using MDX, etc.  Various reports such as: - Agreed Work Load By Fee Earners for the PI Client Intake Commitee. - Report Audit: List of the reports sorted by the frequency that they are being used and by who. - Created a SSIS package including a C# component that scan the Active Directory Tree and then create an Active Directory Database. The goal is to monitor the different level of authorisation each employee get allocated by the different I.T team in the UK. Modeling the outcome of our Marketing campaigns in terms using Data mining algorithms (using R) as well as providing various analysis on the variance of several metrics (such as the length of time it takes for matters to be opened, to become profitable, etc).  Optimization: - Optimizing Dashboard stored procedures using various indexing strategies as well as dynamical sql to control the use of the query plan cache. - Optimizing the loading of the DataWarehouse by exploiting parallel processing in SSIS and other various techniques (rewriting the package avoiding the use of lookups, etc)."}, {"title": "Business Intelligence Developer", "duration": 41, "description": "My main role was to deal with the data migration projects. I was in charge of Migrating Data from legacy applications (legal account software such as Opsis, Osprey, Quill, SOS, Axxia, AlphaLaw, AIM, etc) into our legal account software (DPS Software). Here were my main activities: *Collect and analyse the project\u2019s business requirements with the stakeholders *Create process to extract, transform and load (ETL) data from legacy systems using SSIS. *Investigate and rectify technical issues within the ETL process. *Interact with internal and external teams to troubleshoot any issue in data migration cycle. *Create and maintain technical documentation  My second role was to develop Business Intelligence services. I was working on a variety of greenfield projects for my firm as well as for our clients. My main activities: *MS BI Stack - SSIS , SSRS *Develop new BI services *Responsible for developing all the SSRS reports and dashboards (bespoke as well as the one that get included into our legal account software) *When required I assist the Software Developers in writing T-SQL (Stored Procedures, Functions, Triggers, etc) *Develop data warehouse to allow to create reports for the system engineers or the sales team. "}], "skills": ["SSRS", "C#", "SSIS", "T-SQL", "VBA", "R", "SQL Server Reporting Services (SSRS)", "VBA Excel", "Power BI", "Python"]}}]