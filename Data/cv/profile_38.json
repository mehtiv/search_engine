{"id": 38, "title": "Consultant", "experience": [{"title": "Consultant Data Scientist", "description": "R\u00e9alisation de diff\u00e9rents POCS afin de r\u00e9pondre \u00e0 diff\u00e9rentes probl\u00e9matiques en utilisant le\nMachine Learning & Deep Learning.\n\nChallenge(s) / Objectifs de la mission\n    * Un POC Sur le Marketing pr\u00e9dictif pour le site We Are Tennis du BNP Parisbas ; \n    * Un POC sur l'analyse textuelle d'une base de donn\u00e9es des emails\n\nRessources\n    * L'\u00e9quipe du Data Lab.\n\nT\u00e2ches\n    *    POC sur le Marketing pr\u00e9dictif :\n\n    *    Exploration des donn\u00e9es utilisateurs du site We Are Tennis ; \n    *    Analyse de l'audience\n    *    Analyse du comportement Utilisateurs\n    *    Segmentation des utilisateurs\n\n    *    POC sur l'analyse textuelle d'une base de donn\u00e9es des emails :\n\n    *    Structuration des donn\u00e9es textuelles (contenus des emails) ; \n    *    Nettoyage et standardisation des contenus ; \n    *    Calcul de similarit\u00e9s entre les contenus des mails ; \n    *    R\u00e9aliser un graphe permettant la repr\u00e9sentation des interactions entre les personnes\n\n\nEnvironnement technique/ fonctionnel / m\u00e9thodologie\nR-studio, R machine learning-packages, Python", "duration": 28}, {"title": "Consultant Data scientist/d\u00e9veloppeur", "description": "Projet ayant pour but l'am\u00e9lioration du processus de contr\u00f4le et validation des donn\u00e9es \nfinanci\u00e8res.\n\nChallenge(s) / Objectifs de la mission \n    * Exploration des donn\u00e9es financi\u00e8res (Trade, Cashflow) afin de les comprendre et les maitriser ; \n    * \u00catre capable de valider un fichier contenant un mois de donn\u00e9es via des indicateurs bas\u00e9s sur \n    un benchmark\n\n\n\n    *    \u00catre capable de d\u00e9tecter localement une anomalie au niveau d'un deal dans un fichier d'un mois \n    de donn\u00e9es\n\nRessources\n    * Une \u00e9quipe de 3 data scientists\n\nT\u00e2ches\n    *    Exploration des donn\u00e9es : \n    * R\u00e9cup\u00e9rer plusieurs fichiers de donn\u00e9es de plusieurs mois et diff\u00e9rentes sources du Datalake ; \n    *    D\u00e9couvrir la structure des donn\u00e9es, la typologie des variables ; \n    *    La r\u00e9alisation des statistiques sur chaque fichier, afin de d\u00e9couvrir les variables importantes ; \n    *    La visualisation des donn\u00e9es et les \u00e9tudier variable par variable ; \n    *    L'\u00e9tude des relations entre les variables, les d\u00e9pendances et les corr\u00e9lations ; \n    *    L'identification des variables importantes pour chaque type de donn\u00e9es\n\n    *    Analyse de similarit\u00e9s : \n    * Afin de valider un fichier d'un mois de donn\u00e9es, nous pouvons le comparer au mois \n    pr\u00e9c\u00e9dent ou \u00e0 un benchmark valid\u00e9 pris de des donn\u00e9es historiques selon certaines \n    caract\u00e9ristiques intrins\u00e8ques\n    *    Construire un indicateur de similarit\u00e9 entre deux fichiers de donn\u00e9es, en se basant sur le \n    calcul de similarit\u00e9 des caract\u00e9ristiques statistiques des variables\n    *    Construire un deuxi\u00e8me indicateur de similarit\u00e9 bas\u00e9 sur les caract\u00e9ristiques intrins\u00e8ques \n    des donn\u00e9es, les corr\u00e9lations entre les variables et leurs comportements dans les diff\u00e9rents \n    fichiers\n\n    *    D\u00e9tection d'anomalies : \n    *    Dans le fichier il peut y avoir des anomalies locales au niveau des Deals, il faudra les d\u00e9tecter \n    le plus vite possible\n    *    Pour d\u00e9tecter ces anomalies nous avons r\u00e9alis\u00e9 un mod\u00e8le de d\u00e9tection bas\u00e9 sur\n    l'apprentissage non supervis\u00e9\n\n\n\n    *    Nous avons test\u00e9 diff\u00e9rents algorithmes de d\u00e9tection d'anomalies et adapt\u00e9 les mod\u00e8les \n    selon le type des donn\u00e9es. Les approches de d\u00e9tection d'anomalies test\u00e9es sont :\n    -    Les techniques bas\u00e9es sur le plus proche voisin (k-nearest neighbor, local outlier factor) ; \n    -    Techniques bas\u00e9es sur Clustering (DBSCAN, k-means) ; \n    -    Les mod\u00e8les graphiques probabilistes (r\u00e9seau bay\u00e9sien)\n\nR\u00e9sultats\n    * Bonne Maitrise et compr\u00e9hension des donn\u00e9es et de leurs dynamiques apr\u00e8s la phase \n    exploratoire\n    * R\u00e9alisation des indicateurs de validation globales des fichiers d'un mois de donn\u00e9es financi\u00e8res ; \n    * R\u00e9alisation d'un mod\u00e8le de d\u00e9tection d'anomalies capable d'identifier les deals pr\u00e9sentant des \n    anomalies", "duration": 111}, {"title": "Stage ing\u00e9nieur/analyste", "description": "Stage ing\u00e9nieur : Data analyste & d\u00e9veloppeur\n\nStage effectu\u00e9 au laboratoire de l'ENSTA Paristech en coop\u00e9ration avec PSA.\nChallenge(s) / Objectifs de la mission\n    * \u00c9tudier la sensibilit\u00e9 des dur\u00e9es de vie des pi\u00e8ces automobiles vis-\u00e0-vis des imperfections dans \n    les conditions des tests et du fonctionnement", "duration": 10}]}